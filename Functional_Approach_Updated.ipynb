{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86a509de",
   "metadata": {},
   "source": [
    "### Functional Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ab67c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "# To save the file as parquet format in S3, we use BytesIO\n",
    "from io import StringIO, BytesIO\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "22e607b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapter Layer\n",
    "\n",
    "def read_csv_to_df(bucket, key, decoding = 'utf-8', sep = ','):\n",
    "    csv_obj = bucket.Object(key=key).get().get('Body').read().decode(decoding)\n",
    "    data = StringIO(csv_obj)\n",
    "    df = pd.read_csv(data, delimiter=sep)\n",
    "    return df\n",
    "\n",
    "def write_df_to_s3(bucket, df, key):\n",
    "    out_buffer = BytesIO()\n",
    "    df.to_parquet(out_buffer, index=False)\n",
    "    bucket.put_object(Body=out_buffer.getvalue(), Key=key)\n",
    "    return True\n",
    "\n",
    "def write_df_to_s3_csv(bucket, df, key):\n",
    "    out_buffer = StringIO()\n",
    "    df.to_csv(out_buffer, index=False)\n",
    "    bucket.put_object(Body=out_buffer.getvalue(), Key=key)\n",
    "    return True\n",
    "\n",
    "def list_files_in_prefix(bucket, prefix):\n",
    "    files = [obj.key for obj in bucket.objects.filter(Prefix=prefix)]\n",
    "    return files\n",
    "\n",
    "    #objects = [obj.key for obj in bucket.objects.all() if datetime.strptime(obj.key.split('/')[0], src_format).date() >= min_date\n",
    "    #      and datetime.strptime(obj.key.split('/')[0], src_format).date() <= datetime.strptime(arg_date, src_format).date()]\n",
    "    #return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a90a2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application Layer\n",
    "\n",
    "def extract(bucket, date_list):\n",
    "    files = [key for date in date_list for key in list_files_in_prefix(bucket, date)]\n",
    "    df = pd.concat([read_csv_to_df(bucket, obj) for obj in files], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def transform_report1(df, columns, arg_date):\n",
    "    df = df.loc[:, columns]\n",
    "    df.dropna(inplace=True)\n",
    "    df['opening_price'] = df.sort_values(by = ['Time']).groupby(['ISIN', 'Date'])['StartPrice'].transform('first')\n",
    "    df['closing_price'] = df.sort_values(by = ['Time']).groupby(['ISIN', 'Date'])['StartPrice'].transform('last')\n",
    "    df = df.groupby(['ISIN','Date'], as_index = False).agg(opening_price_eur=('opening_price', 'min'), \n",
    "                                                               closing_price_eur=('closing_price','min'), \n",
    "                                                               minimum_price_eur=('MinPrice','min'), \n",
    "                                                               maximum_price_eur=('MaxPrice','max'), \n",
    "                                                               daily_traded_volume=('TradedVolume','sum'))\n",
    "    df['prev_closing_price'] = df.sort_values(by=['Date']).groupby(['ISIN'])['closing_price_eur'].shift(1)\n",
    "    df['change_prev_closing_%'] = (df['closing_price_eur'] - df['prev_closing_price']) / df['prev_closing_price'] * 100\n",
    "    df.drop(columns=['prev_closing_price'], inplace=True)\n",
    "    df = df.round(decimals=2)\n",
    "    df = df[df.Date >= arg_date]\n",
    "    return df\n",
    "\n",
    "def load(bucket, df, tgt_key, tgt_format, meta_key, extract_date_list):\n",
    "    key = tgt_key + datetime.today().strftime(\"%Y%m%d_%H%M%S\") + tgt_format\n",
    "    write_df_to_s3(bucket, df, key)\n",
    "    update_meta_file(bucket, meta_key, extract_date_list)\n",
    "    return True\n",
    "\n",
    "def etl_report1(src_bucket, tgt_bucket, date_list, columns, arg_date, tgt_key, tgt_format, meta_key):\n",
    "    df = extract(src_bucket, date_list)\n",
    "    df = transform_report1(df, columns, arg_date)\n",
    "    extract_date_list = [date for date in date_list if date >= arg_date]\n",
    "    load(tgt_bucket, df, tgt_key, tgt_format, meta_key, extract_date_list)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e874e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application Layer - not core\n",
    "\n",
    "def return_date_list(bucket, arg_date, src_format, meta_key):\n",
    "    min_date = datetime.strptime(arg_date, src_format).date() - timedelta(days=1)\n",
    "    today = datetime.today().date()\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        df_meta = read_csv_to_df(bucket, meta_key)\n",
    "        dates = [(min_date + timedelta(days=x)) for x in range(0, (today-min_date).days + 1)]\n",
    "        src_dates = set(pd.to_datetime(df_meta['source_date']).dt.date)\n",
    "        dates_missing = set(dates[1:]) - src_dates\n",
    "\n",
    "        if dates_missing:\n",
    "            min_date = min(set(dates[1:]) - src_dates) - timedelta(days=1)\n",
    "            return_dates = [date.strftime(src_format) for date in dates if date >= min_date]\n",
    "            return_min_date = (min_date + timedelta(days=1)).strftime(src_format)\n",
    "        else:\n",
    "            return_dates = []\n",
    "            return_min_date = datetime(2200, 1, 1).date()\n",
    "    \n",
    "    except bucket.session.client('s3').exceptions.NoSuchKey:\n",
    "        return_dates = [(min_date + timedelta(days=x)).strftime(src_format) for x in range(0, (today-min_date).days)]\n",
    "        return_min_date = arg_date\n",
    "        \n",
    "    return return_min_date, return_dates\n",
    "\n",
    "# Function to update metafile in S3 \n",
    "def update_meta_file(bucket, meta_key, extract_date_list):\n",
    "    df_new = pd.DataFrame(columns=['source_date', 'datetime_of_processing'])\n",
    "    df_new['source_date'] = extract_date_list\n",
    "    df_new['datetime_of_processing'] = datetime.today().strftime('%Y-%m-%d')\n",
    "    df_old = read_csv_to_df(bucket, meta_key)\n",
    "    df_all = pd.concat([df_old, df_new])\n",
    "    write_df_to_s3_csv(bucket, df_all, meta_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4944ab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Function Entrypoint\n",
    "\n",
    "def main():\n",
    "    #Parameters/configurations\n",
    "    #Later read config\n",
    "    arg_date = '2022-05-06'\n",
    "    src_format = '%Y-%m-%d'\n",
    "    src_bucket = 'deutsche-boerse-xetra-pds'\n",
    "    tgt_bucket = 'xetra-quickanddirtysolution1234'\n",
    "    columns = ['ISIN', 'Date', 'Time', 'StartPrice', 'MaxPrice', 'MinPrice', 'EndPrice', 'TradedVolume']\n",
    "    tgt_key = 'xetra_daily_report_'\n",
    "    tgt_format = '.parquet'\n",
    "    meta_key = 'meta_file.csv'\n",
    "    \n",
    "    #Init\n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket_src = s3.Bucket(src_bucket)\n",
    "    bucket_tgt = s3.Bucket(tgt_bucket)\n",
    "    \n",
    "    # Run Application\n",
    "    extract_date, date_list = return_date_list(bucket_tgt, arg_date, src_format, meta_key)\n",
    "    print(f'Extract date: {extract_date}')\n",
    "    print()\n",
    "    # Here date_list is the list from arg date to current date and will update meta file in s3 depicting that all the files till today are processed\n",
    "    print(f'Date List: {date_list}')\n",
    "    print()\n",
    "    etl_report1(bucket_src, bucket_tgt, date_list, columns, extract_date, tgt_key, tgt_format, meta_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "797a0f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract date: 2022-05-06\n",
      "\n",
      "Date List: ['2022-05-05', '2022-05-06', '2022-05-07', '2022-05-08', '2022-05-09', '2022-05-10', '2022-05-11', '2022-05-12', '2022-05-13', '2022-05-14', '2022-05-15', '2022-05-16', '2022-05-17', '2022-05-18', '2022-05-19', '2022-05-20', '2022-05-21', '2022-05-22', '2022-05-23', '2022-05-24', '2022-05-25', '2022-05-26', '2022-05-27', '2022-05-28', '2022-05-29', '2022-05-30', '2022-05-31', '2022-06-01', '2022-06-02', '2022-06-03', '2022-06-04', '2022-06-05', '2022-06-06', '2022-06-07', '2022-06-08', '2022-06-09', '2022-06-10', '2022-06-11', '2022-06-12', '2022-06-13', '2022-06-14', '2022-06-15']\n",
      "\n",
      "ETL job executed successfully\n"
     ]
    }
   ],
   "source": [
    "# Execute\n",
    "main()\n",
    "print('ETL job executed successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103fe0e0",
   "metadata": {},
   "source": [
    "### Write to S3 Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a4b449",
   "metadata": {},
   "source": [
    "### Reading the uploaded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7e9c1929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_file.csv\n",
      "xetra_daily_report_20220613_160951.parquet\n",
      "xetra_daily_report_20220614_110223.parquet\n",
      "xetra_daily_report_20220614_114032.parquet\n",
      "xetra_daily_report_20220614_124003.parquet\n",
      "xetra_daily_report_20220615_105344.parquet\n",
      "xetra_daily_report_20220615_110322.parquet\n",
      "xetra_daily_report_20220615_114927.parquet\n",
      "xetra_daily_report_20220615_115114.parquet\n",
      "xetra_daily_report_20220615_115228.parquet\n",
      "xetra_daily_report_20220615_115331.parquet\n",
      "xetra_daily_report_20220615_115504.parquet\n",
      "xetra_daily_report_20220615_115600.parquet\n",
      "xetra_daily_report_20220615_115725.parquet\n",
      "xetra_daily_report_20220615_120045.parquet\n",
      "xetra_daily_report_20220615_121615.parquet\n"
     ]
    }
   ],
   "source": [
    "tgt_bucket = 'xetra-quickanddirtysolution1234'\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_tgt = s3.Bucket(tgt_bucket)\n",
    "for obj in bucket_tgt.objects.all():\n",
    "    print(obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "17cbba1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Date</th>\n",
       "      <th>opening_price_eur</th>\n",
       "      <th>closing_price_eur</th>\n",
       "      <th>minimum_price_eur</th>\n",
       "      <th>maximum_price_eur</th>\n",
       "      <th>daily_traded_volume</th>\n",
       "      <th>change_prev_closing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-05-06</td>\n",
       "      <td>36.30</td>\n",
       "      <td>36.15</td>\n",
       "      <td>36.15</td>\n",
       "      <td>36.50</td>\n",
       "      <td>350</td>\n",
       "      <td>-3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>36.15</td>\n",
       "      <td>35.30</td>\n",
       "      <td>35.30</td>\n",
       "      <td>36.15</td>\n",
       "      <td>125</td>\n",
       "      <td>-2.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-05-10</td>\n",
       "      <td>35.80</td>\n",
       "      <td>35.25</td>\n",
       "      <td>35.25</td>\n",
       "      <td>35.90</td>\n",
       "      <td>310</td>\n",
       "      <td>-0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-05-11</td>\n",
       "      <td>36.55</td>\n",
       "      <td>36.30</td>\n",
       "      <td>35.90</td>\n",
       "      <td>36.55</td>\n",
       "      <td>540</td>\n",
       "      <td>2.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>36.30</td>\n",
       "      <td>35.80</td>\n",
       "      <td>35.80</td>\n",
       "      <td>36.30</td>\n",
       "      <td>295</td>\n",
       "      <td>-1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19873</th>\n",
       "      <td>XS2437455608</td>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>26.45</td>\n",
       "      <td>29.24</td>\n",
       "      <td>26.45</td>\n",
       "      <td>29.24</td>\n",
       "      <td>0</td>\n",
       "      <td>10.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19874</th>\n",
       "      <td>XS2437455608</td>\n",
       "      <td>2022-05-10</td>\n",
       "      <td>28.32</td>\n",
       "      <td>29.32</td>\n",
       "      <td>28.32</td>\n",
       "      <td>29.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19875</th>\n",
       "      <td>XS2437455608</td>\n",
       "      <td>2022-05-11</td>\n",
       "      <td>28.54</td>\n",
       "      <td>27.39</td>\n",
       "      <td>27.39</td>\n",
       "      <td>28.54</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19876</th>\n",
       "      <td>XS2437455608</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>28.86</td>\n",
       "      <td>27.77</td>\n",
       "      <td>27.77</td>\n",
       "      <td>28.93</td>\n",
       "      <td>0</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19877</th>\n",
       "      <td>XS2437455608</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>25.94</td>\n",
       "      <td>24.91</td>\n",
       "      <td>24.91</td>\n",
       "      <td>25.94</td>\n",
       "      <td>0</td>\n",
       "      <td>-10.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19878 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ISIN        Date  opening_price_eur  closing_price_eur  \\\n",
       "0      AT000000STR1  2022-05-06              36.30              36.15   \n",
       "1      AT000000STR1  2022-05-09              36.15              35.30   \n",
       "2      AT000000STR1  2022-05-10              35.80              35.25   \n",
       "3      AT000000STR1  2022-05-11              36.55              36.30   \n",
       "4      AT000000STR1  2022-05-12              36.30              35.80   \n",
       "...             ...         ...                ...                ...   \n",
       "19873  XS2437455608  2022-05-09              26.45              29.24   \n",
       "19874  XS2437455608  2022-05-10              28.32              29.32   \n",
       "19875  XS2437455608  2022-05-11              28.54              27.39   \n",
       "19876  XS2437455608  2022-05-12              28.86              27.77   \n",
       "19877  XS2437455608  2022-05-13              25.94              24.91   \n",
       "\n",
       "       minimum_price_eur  maximum_price_eur  daily_traded_volume  \\\n",
       "0                  36.15              36.50                  350   \n",
       "1                  35.30              36.15                  125   \n",
       "2                  35.25              35.90                  310   \n",
       "3                  35.90              36.55                  540   \n",
       "4                  35.80              36.30                  295   \n",
       "...                  ...                ...                  ...   \n",
       "19873              26.45              29.24                    0   \n",
       "19874              28.32              29.32                    0   \n",
       "19875              27.39              28.54                    0   \n",
       "19876              27.77              28.93                    0   \n",
       "19877              24.91              25.94                    0   \n",
       "\n",
       "       change_prev_closing_%  \n",
       "0                      -3.08  \n",
       "1                      -2.35  \n",
       "2                      -0.14  \n",
       "3                       2.98  \n",
       "4                      -1.38  \n",
       "...                      ...  \n",
       "19873                  10.84  \n",
       "19874                   0.27  \n",
       "19875                  -6.60  \n",
       "19876                   1.39  \n",
       "19877                 -10.29  \n",
       "\n",
       "[19878 rows x 8 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_obj = bucket_tgt.Object(key='xetra_daily_report_20220615_121615.parquet').get().get('Body').read()\n",
    "data = BytesIO(par_obj)\n",
    "df_report = pd.read_parquet(data)\n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f744458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
